{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86a0e90f-ea6c-49a6-8f9c-4cc1d89706a1",
   "metadata": {},
   "source": [
    "# 02 - Loading Data\n",
    "TEEHR comes with utilities to fetch and format data from a few different sources and store to the TEEHR data format.  We are open to adding more, but also attempted to make the format simple enough that getting your own data into the TEEHR format should be relatively easy - create a Pandas DataFrame with the correct column names and save a Parquet file.\n",
    "\n",
    "## The included loading utilities are:\n",
    "\n",
    "- NWM v2.1 and NWM v2.2 feature data in Google Cloud\n",
    "- NWM v2.1 and NWM v2.2 forcing data in Google Cloud \n",
    "- NWM v2.0 and NWM v2.1 Retrospective in AWS\n",
    "- USGS NWIS Data\n",
    "\n",
    "This covers both feature data (e.g., data at NWM features) as well as aggregated grid data (e.g., mean areal precipitation for catchments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f27a0003-e9be-4f1d-9e83-790ad3148609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import teehr.loading.nwm_point_data as nwmp\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5d5e691-506d-46ee-9f66-e18e5de09a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mnwmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnwm_to_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moutput_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvariable_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstart_date\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mingest_days\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlocation_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mjson_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moutput_parquet_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mt_minus_hours\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Fetches NWM point data, formats to tabular, and saves to parquet\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "run : str\n",
      "    NWM forecast category.\n",
      "    (e.g., \"analysis_assim\", \"short_range\", ...)\n",
      "output_type : str\n",
      "    Output component of the configuration.\n",
      "    (e.g., \"channel_rt\", \"reservoir\", ...)\n",
      "variable_name : str\n",
      "    Name of the NWM data variable to download.\n",
      "    (e.g., \"streamflow\", \"velocity\", ...)\n",
      "start_date : str or datetime\n",
      "    Date to begin data ingest.\n",
      "    Str formats can include YYYY-MM-DD or MM/DD/YYYY\n",
      "ingest_days : int\n",
      "    Number of days to ingest data after start date\n",
      "location_ids : Iterable[int]\n",
      "    Array specifying NWM IDs of interest\n",
      "json_dir : str\n",
      "    Directory path for saving json reference files\n",
      "output_parquet_dir : str\n",
      "    Path to the directory for the final parquet files\n",
      "t_minus_hours: Optional[Iterable[int]]\n",
      "    Specifies the look-back hours to include if an assimilation\n",
      "    run is specified.\n",
      "\n",
      "The NWM configuration variables, including run, output_type, and\n",
      "variable_name are stored in the NWM22_RUN_CONFIG dictionary in\n",
      "const_nwm.py.\n",
      "\n",
      "Forecast and assimilation data is grouped and saved one file per reference\n",
      "time, using the file name convention \"YYYYMMDDTHHZ\".  The tabular output\n",
      "parquet files follow the timeseries data model described here:\n",
      "https://github.com/RTIInternational/teehr/blob/main/docs/data_models.md#timeseries  # noqa\n",
      "\u001b[0;31mFile:\u001b[0m      ~/repos/teehr/src/teehr/loading/nwm_point_data.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "?nwmp.nwm_to_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2745dba2-b125-429d-a1e6-21c434e0fae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some notebook variables to point to the relevant study files.  \n",
    "RUN = \"short_range\"\n",
    "OUTPUT_TYPE = \"channel_rt\"\n",
    "VARIABLE_NAME = \"streamflow\"\n",
    "\n",
    "START_DATE = \"2023-03-18\"\n",
    "INGEST_DAYS = 1\n",
    "\n",
    "OUTPUT_ROOT = Path(Path().home(), \"cache\")\n",
    "JSON_DIR = Path(OUTPUT_ROOT, \"zarr\", RUN)\n",
    "OUTPUT_DIR = Path(OUTPUT_ROOT, \"timeseries\", RUN)\n",
    "\n",
    "# For this simple example, we'll get data for 10 NWM reaches that coincide with USGS gauges\n",
    "LOCATION_IDS = [7086109,  7040481,  7053819,  7111205,  7110249, 14299781, 14251875, 14267476,  7152082, 14828145]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c60d48e-1847-498d-9909-d004c7693a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(n_workers=8)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a1ec7-a8ca-45cd-869d-a3c7bcc26b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nwmp.nwm_to_parquet(\n",
    "    RUN,\n",
    "    OUTPUT_TYPE,\n",
    "    VARIABLE_NAME,\n",
    "    START_DATE,\n",
    "    INGEST_DAYS,\n",
    "    LOCATION_IDS,\n",
    "    JSON_DIR,\n",
    "    OUTPUT_DIR\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e13aa731-9cb0-4540-a357-1603b52de29b",
   "metadata": {},
   "source": [
    "## Cached Data\n",
    "We cached several datasets on AWI's 2i2c JupyterHub shared drive for this workshop.\n",
    "\n",
    "List datasets here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
