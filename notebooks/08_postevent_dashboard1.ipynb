{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34bd4f94-926f-4a54-9a77-3e466f580d15",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 08 - Post-Event Dashboard 1\n",
    "\n",
    "Now we will build a more complete dashboard using some powerful Holoviews functionality to link visualizations and really go exploring.  This example queries all reference times within a single event period and returns metric results for each individual reference time (groupby reference time).  For a single event, many common statistical metrics (e.g., NSE) are not meaningful.  The goal of this dashboard is to instead facilitate qualitative exploration of trends and agreement in the timeseries characteristics (e.g., peak and time to peak) for user selected subsets based on attributes and basic error trends.  This example was built for a specific post-event evaluation need within OWP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efca43-3791-4e08-a82e-73e0b571ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import teehr.queries.duckdb as tqd\n",
    "import postevent_dashboard_utils as du\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import holoviews as hv\n",
    "from holoviews.element import tiles\n",
    "import geoviews as gv\n",
    "import panel as pn\n",
    "import hvplot\n",
    "import hvplot.pandas\n",
    "import colorcet as cc\n",
    "hv.extension('bokeh', logo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435147c1-0704-497d-aa10-d4a37432dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall study directory\n",
    "CACHE_DIR = Path(Path.home(), \"shared\", \"teehr-workshop\", \"post-event-example\")\n",
    "\n",
    "# medium range streamflow forecast evaluation files \n",
    "MRF_streamflow = dict(\n",
    "    scenario_name=\"medium_range\",\n",
    "    variable=\"streamflow\",\n",
    "    primary_filepath=Path(CACHE_DIR, \"timeseries\", \"usgs\", \"*.parquet\"),\n",
    "    secondary_filepath=Path(CACHE_DIR, \"timeseries\", \"medium_range_mem1\", \"*.parquet\"),\n",
    "    crosswalk_filepath=Path(CACHE_DIR, \"geo\", \"usgs_nwm22_crosswalk.parquet\"),\n",
    "    geometry_filepath=Path(CACHE_DIR, \"geo\", \"usgs_geometry.parquet\")\n",
    ")\n",
    "# medium range precip forecast evaluation files\n",
    "MRF_forcing = dict(\n",
    "    scenario_name=\"medium_range\",\n",
    "    variable=\"precipitation\",    \n",
    "    primary_filepath=Path(CACHE_DIR, \"timeseries\", \"forcing_analysis_assim\", \"*.parquet\"),\n",
    "    secondary_filepath=Path(CACHE_DIR, \"timeseries\", \"forcing_medium_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=Path(CACHE_DIR, \"geo\", \"huc10_huc10_crosswalk.parquet\"),\n",
    "    geometry_filepath=Path(CACHE_DIR, \"geo\", \"huc10_geometry.parquet\"),\n",
    ")\n",
    "# short range streamflow forecast evaluation files \n",
    "SRF_streamflow = dict(\n",
    "    scenario_name=\"short_range\",\n",
    "    variable=\"streamflow\",\n",
    "    primary_filepath=MRF_streamflow[\"primary_filepath\"],\n",
    "    secondary_filepath=Path(CACHE_DIR, \"timeseries\", \"short_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=MRF_streamflow[\"crosswalk_filepath\"],\n",
    "    geometry_filepath=MRF_streamflow[\"geometry_filepath\"],\n",
    ")\n",
    "# medium range precip forecast evaluation files\n",
    "SRF_forcing = dict(\n",
    "    scenario_name=\"short_range\",\n",
    "    variable=\"precipitation\",    \n",
    "    primary_filepath=MRF_forcing[\"primary_filepath\"],\n",
    "    secondary_filepath=Path(CACHE_DIR, \"timeseries\", \"forcing_short_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=MRF_forcing[\"crosswalk_filepath\"],\n",
    "    geometry_filepath=MRF_forcing[\"geometry_filepath\"],\n",
    ")\n",
    "attribute_paths = dict(\n",
    "    usgs_upstream_area=Path(CACHE_DIR, \"geo\", \"usgs_attr_upstream_area.parquet\"),\n",
    "    usgs_ecoregions=Path(CACHE_DIR, \"geo\", \"usgs_attr_ecoregions.parquet\"),\n",
    "    usgs_stream_order=Path(CACHE_DIR, \"geo\", \"usgs_attr_stream_order.parquet\"),\n",
    "    usgs_huc_crosswalk=Path(CACHE_DIR, \"geo\", \"usgs_huc12_crosswalk.parquet\"),\n",
    ")\n",
    "\n",
    "# put the scenarios in a list for widget purposes\n",
    "scenario_definitions = [MRF_streamflow, MRF_forcing, SRF_streamflow, SRF_forcing]\n",
    "\n",
    "## general units ('english' or 'metric') to show in visualization\n",
    "viz_units = \"metric\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb0b3d-e116-4bfa-9057-1e4cefbffeae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select the forecast scenario, time periods and region of interest\n",
    "The next two cells are a subset of the widgets demonstrated in notebook 07 that are relevant for this example.  These widgets will also eventually be merged into the main dashboard interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb21d7f-b46f-4311-9442-c82cb296846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_selector = du.get_scenario_selector(scenario_name_list=sorted(du.get_scenario_names(scenario_definitions)))\n",
    "scenario_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f36dbd-5777-4e78-8d33-8c7d186d6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamflow_scenario = du.get_scenario(scenario_definitions, scenario_name=scenario_selector.value, variable='streamflow')\n",
    "forcing_scenario = du.get_scenario(scenario_definitions, scenario_name=scenario_selector.value, variable='precipitation')\n",
    "widgets = du.get_filter_widgets(scenario=streamflow_scenario, include_widgets=['value_time','reference_time','huc2','metrics'])\n",
    "pn.Row(\n",
    "    pn.Column(widgets['huc2'], widgets['metrics']),\n",
    "    pn.Spacer(width=50),\n",
    "    pn.Column(widgets['value_time'], widgets['reference_time'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c7d1c-88fb-4866-9246-f26f50d74c45",
   "metadata": {},
   "source": [
    "### Get observed and forecast timeseries characteristics and join with some attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f34352-3cfb-4f9a-817b-22b716d9e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gdf = du.run_teehr_query(\n",
    "    query_type=\"metrics\",\n",
    "    scenario=streamflow_scenario,\n",
    "    huc_id=widgets['huc2'].value,\n",
    "    value_time_start=widgets['value_time'][1].value_start,    \n",
    "    value_time_end=widgets['value_time'][1].value_end,    \n",
    "    reference_time_start=widgets['reference_time'][1].value_start,    \n",
    "    reference_time_end=widgets['reference_time'][1].value_end,\n",
    "    group_by=['primary_location_id','reference_time'],\n",
    "    order_by=['primary_location_id','reference_time'], \n",
    "    include_metrics=widgets['metrics'].value,\n",
    "    value_min=0,\n",
    "    attribute_paths=attribute_paths,\n",
    ")\n",
    "display(gdf.head())\n",
    "\n",
    "# convert units, add attributes\n",
    "gdf = du.convert_query_to_viz_units(gdf, viz_units, streamflow_scenario['variable'])\n",
    "attribute_df = du.combine_attributes(attribute_paths, viz_units)\n",
    "gdf = du.merge_attr_to_gdf(gdf, attribute_df)\n",
    "\n",
    "# replace geometry with easting and northing to facilitate linked plots\n",
    "df = gdf[[c for c in gdf.columns if c not in ['geometry','measurement_unit']]].copy()\n",
    "df['latitude'] = gdf.geometry.y\n",
    "df['easting'] = gdf.to_crs(\"EPSG:3857\").geometry.x\n",
    "df['northing'] = gdf.to_crs(\"EPSG:3857\").geometry.y\n",
    "\n",
    "# calculate the peak flow percent difference and peak time difference in hours\n",
    "if all(x in df.columns for x in ['max_value_delta', 'primary_maximum']):\n",
    "    df['max_perc_diff'] = df['max_value_delta']/df['primary_maximum']*100\n",
    "    df.loc[df['max_perc_diff'] == np.inf, 'max_perc_diff'] = np.nan\n",
    "if all(x in df.columns for x in ['max_value_timedelta']):\n",
    "    df['max_time_diff'] = (df['max_value_timedelta'] / np.timedelta64(1, 'h')).astype(int)\n",
    "\n",
    "# turn the string ecoregion into unique integers to enable histograms\n",
    "eco_df = pd.DataFrame(df['ecoregion_L2'].unique())\n",
    "eco_df['num']=eco_df[0].str[0:4].astype('float')\n",
    "eco_df = eco_df.sort_values('num').reset_index()\n",
    "eco_list=list(eco_df[0])\n",
    "df['ecoregion_int'] = [eco_list.index(e)+1 for e in df['ecoregion_L2']]\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c7f97c-49cb-454a-9675-85f9bac9e4b0",
   "metadata": {},
   "source": [
    "### Build an interactive dashboard to explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4bfbb-b3f4-48ab-bedf-2048eba4fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_column_options = ['stream_order','ecoregion_int','upstream_area','latitude','max_perc_diff','max_time_diff']\n",
    "color_variable_selector = pn.widgets.Select(name='Color Variable', \n",
    "                                          options=du.get_metric_selector_dict(color_column_options,scenario_selector.value),\n",
    "                                          value=color_column_options[0], \n",
    "                                          width_policy=\"fit\")\n",
    "\n",
    "scatter_variable_options=['Peak Flow','Peak Time']\n",
    "scatter_variable_selector = pn.widgets.Select(name='Scatter Variable', \n",
    "                                          options=scatter_variable_options, \n",
    "                                          value=scatter_variable_options[0], \n",
    "                                          width_policy=\"fit\")\n",
    "\n",
    "basemap = tiles.CartoLight().redim(x='easting', y='northing')\n",
    "df_sub = df.drop_duplicates(subset=['primary_location_id'], keep='first')\n",
    "points = pn.bind(\n",
    "    du.get_points,\n",
    "    df=df_sub, \n",
    "    color_variable=color_variable_selector.param.value, \n",
    "    scenario_name=scenario_selector.value,\n",
    "    units=viz_units,\n",
    "    opts=dict(width=500, height=400)\n",
    ")\n",
    "scatter = pn.bind(\n",
    "    du.get_scatter,\n",
    "    df=df, \n",
    "    scatter_variable=scatter_variable_selector.param.value, \n",
    "    color_variable=color_variable_selector.param.value, \n",
    "    scenario_name=scenario_selector.value,\n",
    "    units=viz_units,\n",
    "    opts=dict(width=400, height=400)\n",
    ")\n",
    "area_hist = du.get_histogram(df, column='upstream_area', nbins=50)\n",
    "peak_diff_hist = du.get_histogram(df, column='max_perc_diff', nbins=50)\n",
    "peak_timediff_hist = du.get_histogram(df, column='max_time_diff', nbins=50)\n",
    "eco_hist =   du.get_categorical_histogram(df, column = 'ecoregion_int', labels=eco_df['num'])\n",
    "order_hist = du.get_categorical_histogram(df, column = 'stream_order')\n",
    "\n",
    "area_hist.         opts(width=300, height=200)\n",
    "peak_diff_hist.    opts(width=300, height=200)\n",
    "peak_timediff_hist.opts(width=300, height=200)\n",
    "eco_hist.          opts(width=250, height=200)\n",
    "order_hist.        opts(width=250, height=200)\n",
    "\n",
    "scenario_text = du.get_scenario_text(scenario_selector.value)\n",
    "subtitle = f\"Example 1: Forecast Data Exploration<br> - {scenario_text}\"\n",
    "header = du.get_dashboard_header(subtitle)\n",
    "\n",
    "ls = hv.link_selections.instance()\n",
    "\n",
    "pn.Column(\n",
    "    pn.Column(pn.Spacer(height=10), header, width=1100),\n",
    "    pn.Row(\n",
    "        pn.Spacer(height=20),\n",
    "        pn.Column(pn.Spacer(height=20), scatter_variable_selector, color_variable_selector, width=200),\n",
    "        pn.Row(ls(hv.DynamicMap(scatter)) + basemap*ls(hv.DynamicMap(points))),\n",
    "    ),  \n",
    "    pn.Row(ls(peak_diff_hist + peak_timediff_hist + order_hist + eco_hist)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13829d31-b51c-4e25-bbdf-911ebb559912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
