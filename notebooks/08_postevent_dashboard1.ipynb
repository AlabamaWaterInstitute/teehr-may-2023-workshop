{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f28e53-63b8-48e1-8017-0c4c85997cae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TEEHR Post-Event Example 1\n",
    "### Explore Forecast Evaluation Trends and Relationships\n",
    "\n",
    "Add more text description about this use case....\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777e449-4585-453a-be09-84e2a98645ae",
   "metadata": {},
   "source": [
    "### Install and Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a992e6-c34d-42bf-a1a6-acb6d680b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install 'teehr @ git+https://@github.com/RTIInternational/teehr@main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efca43-3791-4e08-a82e-73e0b571ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import teehr.queries.duckdb as tqd\n",
    "\n",
    "import postevent_dashboard_utils as du\n",
    "import importlib\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import holoviews as hv\n",
    "from holoviews.element import tiles\n",
    "import geoviews as gv\n",
    "import panel as pn\n",
    "import hvplot\n",
    "import hvplot.pandas\n",
    "import colorcet as cc\n",
    "\n",
    "hv.extension('bokeh', logo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435147c1-0704-497d-aa10-d4a37432dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation study directory\n",
    "STUDY_DIR = Path(\"/home\", \"jovyan\", \"shared\", \"rti-eval\", \"post-event-example\")\n",
    "\n",
    "## general units ('english' or 'metric') to show in visualization\n",
    "viz_units = \"metric\"\n",
    "\n",
    "# evaluation scenario definitions - specific variables and configurations to be compared within the overall study\n",
    "\n",
    "# medium range streamflow forecast evaluation files \n",
    "MRF_streamflow = dict(\n",
    "    scenario_name=\"medium_range\",\n",
    "    variable=\"streamflow\",\n",
    "    primary_filepath=Path(STUDY_DIR, \"timeseries\", \"usgs\", \"*.parquet\"),\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"medium_range_mem1\", \"*.parquet\"),\n",
    "    crosswalk_filepath=Path(STUDY_DIR, \"geo\", \"usgs_nwm22_crosswalk.parquet\"),\n",
    "    geometry_filepath=Path(STUDY_DIR, \"geo\", \"usgs_geometry.parquet\")\n",
    ")\n",
    "\n",
    "# medium range precip forecast evaluation files\n",
    "MRF_forcing = dict(\n",
    "    scenario_name=\"medium_range\",\n",
    "    variable=\"precipitation\",    \n",
    "    primary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_analysis_assim\", \"*.parquet\"),\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_medium_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=Path(STUDY_DIR, \"geo\", \"huc10_huc10_crosswalk.parquet\"),                    # the primary and secondary are both HUC10\n",
    "    geometry_filepath=Path(STUDY_DIR, \"geo\", \"huc10_geometry.parquet\"),\n",
    ")\n",
    "\n",
    "# short range streamflow forecast evaluation files \n",
    "SRF_streamflow = dict(\n",
    "    scenario_name=\"short_range\",\n",
    "    variable=\"streamflow\",\n",
    "    primary_filepath=MRF_streamflow[\"primary_filepath\"],\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"short_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=MRF_streamflow[\"crosswalk_filepath\"],\n",
    "    geometry_filepath=MRF_streamflow[\"geometry_filepath\"],\n",
    ")\n",
    "\n",
    "# medium range precip forecast evaluation files\n",
    "SRF_forcing = dict(\n",
    "    scenario_name=\"short_range\",\n",
    "    variable=\"precipitation\",    \n",
    "    primary_filepath=MRF_forcing[\"primary_filepath\"],\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_short_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=MRF_forcing[\"crosswalk_filepath\"],\n",
    "    geometry_filepath=MRF_forcing[\"geometry_filepath\"],\n",
    ")\n",
    "\n",
    "scenario_definitions = [MRF_streamflow, MRF_forcing, SRF_streamflow, SRF_forcing]\n",
    "\n",
    "attribute_paths = dict(\n",
    "    usgs_upstream_area=Path(STUDY_DIR, \"geo\", \"usgs_attr_upstream_area.parquet\"),\n",
    "    usgs_ecoregions=Path(STUDY_DIR, \"geo\", \"usgs_attr_ecoregions.parquet\"),\n",
    "    usgs_stream_order=Path(STUDY_DIR, \"geo\", \"usgs_attr_stream_order.parquet\"),\n",
    "    usgs_huc_crosswalk=Path(STUDY_DIR, \"geo\", \"usgs_huc12_crosswalk.parquet\"),\n",
    ")\n",
    "attribute_df = du.combine_attributes(attribute_paths,viz_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb0b3d-e116-4bfa-9057-1e4cefbffeae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Select the forecast scenario, time periods and region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb21d7f-b46f-4311-9442-c82cb296846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_selector = du.get_scenario_selector(scenario_name_list=sorted(du.get_scenario_names(scenario_definitions)))\n",
    "scenario_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f36dbd-5777-4e78-8d33-8c7d186d6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "streamflow_scenario = du.get_scenario(scenario_definitions, scenario_name=scenario_selector.value, variable='streamflow')\n",
    "forcing_scenario = du.get_scenario(scenario_definitions, scenario_name=scenario_selector.value, variable='precipitation')\n",
    "widgets = du.get_filter_widgets(scenario=streamflow_scenario, include_widgets=['value_time','reference_time','huc2','metrics'])\n",
    "pn.Row(\n",
    "    pn.Column(widgets['huc2'], widgets['metrics']),\n",
    "    pn.Spacer(width=50),\n",
    "    pn.Column(widgets['value_time'], widgets['reference_time'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c7d1c-88fb-4866-9246-f26f50d74c45",
   "metadata": {},
   "source": [
    "### Get the observed and forecast peak flows for the above specifications and join with some attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f34352-3cfb-4f9a-817b-22b716d9e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "importlib.reload(du)\n",
    "\n",
    "gdf = du.run_teehr_query(\n",
    "    query_type=\"metrics\",\n",
    "    scenario=streamflow_scenario,\n",
    "    huc_id=widgets['huc2'].value,\n",
    "    value_time_start=widgets['value_time'][1].value_start,    \n",
    "    value_time_end=widgets['value_time'][1].value_end,    \n",
    "    reference_time_start=widgets['reference_time'][1].value_start,    \n",
    "    reference_time_end=widgets['reference_time'][1].value_end,\n",
    "    group_by=['primary_location_id','reference_time'],\n",
    "    order_by=['primary_location_id','reference_time'], \n",
    "    include_metrics=widgets['metrics'].value,\n",
    "    value_min=0,\n",
    "    attribute_paths=attribute_paths,\n",
    ")\n",
    "display(gdf.head())\n",
    "len(gdf)\n",
    "\n",
    "# convert units, add attributes\n",
    "gdf = du.convert_query_to_viz_units(gdf, viz_units, streamflow_scenario['variable'])\n",
    "attribute_df = du.combine_attributes(attribute_paths, viz_units)\n",
    "gdf = du.merge_attr_to_gdf(gdf, attribute_df)\n",
    "\n",
    "# replace geometry with easting and northing to facilitate linked plots\n",
    "df = gdf[[c for c in gdf.columns if c not in ['geometry','measurement_unit']]].copy()\n",
    "df['latitude'] = gdf.geometry.y\n",
    "df['easting'] = gdf.to_crs(\"EPSG:3857\").geometry.x\n",
    "df['northing'] = gdf.to_crs(\"EPSG:3857\").geometry.y\n",
    "\n",
    "if all(x in df.columns for x in ['max_value_delta', 'primary_maximum']):\n",
    "    df['max_perc_diff'] = df['max_value_delta']/df['primary_maximum']*100\n",
    "    df.loc[df['max_perc_diff'] == np.inf, 'max_perc_diff'] = np.nan\n",
    "    \n",
    "if all(x in df.columns for x in ['max_value_timedelta']):\n",
    "    df['max_time_diff'] = (df['max_value_timedelta'] / np.timedelta64(1, 'h')).astype(int)\n",
    "\n",
    "# turn the string ecoregion into unique integers to enable histograms\n",
    "eco_df = pd.DataFrame(df['ecoregion_L2'].unique())\n",
    "eco_df['num']=eco_df[0].str[0:4].astype('float')\n",
    "eco_df = eco_df.sort_values('num').reset_index()\n",
    "eco_list=list(eco_df[0])\n",
    "df['ecoregion_int'] = [eco_list.index(e)+1 for e in df['ecoregion_L2']]\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c7f97c-49cb-454a-9675-85f9bac9e4b0",
   "metadata": {},
   "source": [
    "### Build an interactive dashboard to explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4bfbb-b3f4-48ab-bedf-2048eba4fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "\n",
    "color_column_options = ['stream_order','ecoregion_int','upstream_area','latitude','max_perc_diff','max_time_diff']\n",
    "color_variable_selector = pn.widgets.Select(name='Color Variable', \n",
    "                                          options=du.get_metric_selector_dict(color_column_options,scenario_selector.value),\n",
    "                                          value=color_column_options[0], \n",
    "                                          width_policy=\"fit\")\n",
    "\n",
    "scatter_variable_options=['Peak Flow','Peak Time']\n",
    "scatter_variable_selector = pn.widgets.Select(name='Scatter Variable', \n",
    "                                          options=scatter_variable_options, \n",
    "                                          value=scatter_variable_options[0], \n",
    "                                          width_policy=\"fit\")\n",
    "\n",
    "basemap = tiles.CartoLight().redim(x='easting', y='northing')\n",
    "df_sub = df.drop_duplicates(subset=['primary_location_id'], keep='first')\n",
    "points = pn.bind(\n",
    "    du.get_points,\n",
    "    df=df_sub, \n",
    "    color_variable=color_variable_selector.param.value, \n",
    "    scenario_name=scenario_selector.value,\n",
    "    units=viz_units,\n",
    "    opts=dict(width=500, height=400)\n",
    ")\n",
    "scatter = pn.bind(\n",
    "    du.get_scatter,\n",
    "    df=df, \n",
    "    scatter_variable=scatter_variable_selector.param.value, \n",
    "    color_variable=color_variable_selector.param.value, \n",
    "    scenario_name=scenario_selector.value,\n",
    "    units=viz_units,\n",
    "    opts=dict(width=400, height=400)\n",
    ")\n",
    "area_hist = du.get_histogram(df, column='upstream_area', nbins=50)\n",
    "peak_diff_hist = du.get_histogram(df, column='max_perc_diff', nbins=50)\n",
    "peak_timediff_hist = du.get_histogram(df, column='max_time_diff', nbins=50)\n",
    "eco_hist =   du.get_categorical_histogram(df, column = 'ecoregion_int', labels=eco_df['num'])\n",
    "order_hist = du.get_categorical_histogram(df, column = 'stream_order')\n",
    "\n",
    "area_hist.         opts(width=300, height=200)\n",
    "peak_diff_hist.    opts(width=300, height=200)\n",
    "peak_timediff_hist.opts(width=300, height=200)\n",
    "eco_hist.          opts(width=250, height=200)\n",
    "order_hist.        opts(width=250, height=200)\n",
    "\n",
    "scenario_text = du.get_scenario_text(scenario_selector.value)\n",
    "subtitle = f\"Example 1: Forecast Data Exploration<br> - {scenario_text}\"\n",
    "header = du.get_dashboard_header(subtitle)\n",
    "\n",
    "ls = hv.link_selections.instance()\n",
    "\n",
    "pn.Column(\n",
    "    pn.Column(pn.Spacer(height=10), header, width=1100),\n",
    "    pn.Row(\n",
    "        pn.Spacer(height=20),\n",
    "        pn.Column(pn.Spacer(height=20), scatter_variable_selector, color_variable_selector, width=200),\n",
    "        pn.Row(ls(hv.DynamicMap(scatter)) + basemap*ls(hv.DynamicMap(points))),\n",
    "    ),  \n",
    "    pn.Row(ls(peak_diff_hist + peak_timediff_hist + order_hist + eco_hist)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c0363-c8c1-431a-a38f-1c5e4f98e55d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
