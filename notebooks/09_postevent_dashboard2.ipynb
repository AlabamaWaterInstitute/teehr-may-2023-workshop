{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f28e53-63b8-48e1-8017-0c4c85997cae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TEEHR Post-Event Example 2\n",
    "### Explore Observed and Forecast Timeseries from a Recent Flood Event\n",
    "\n",
    "Add more text description about this use case....\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777e449-4585-453a-be09-84e2a98645ae",
   "metadata": {},
   "source": [
    "### Install and Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a992e6-c34d-42bf-a1a6-acb6d680b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#!pip install 'teehr @ git+https://@github.com/RTIInternational/teehr@main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efca43-3791-4e08-a82e-73e0b571ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import teehr.queries.duckdb as tqd\n",
    "\n",
    "import postevent_dashboard_utils as du\n",
    "import importlib\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import holoviews as hv\n",
    "from holoviews.element import tiles\n",
    "import geoviews as gv\n",
    "import panel as pn\n",
    "hv.extension('bokeh', logo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435147c1-0704-497d-aa10-d4a37432dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation study directory\n",
    "STUDY_DIR = Path(\"/home\", \"jovyan\", \"shared\", \"rti-eval\", \"post-event-example\")\n",
    "\n",
    "## general units ('english' or 'metric') to show in visualization\n",
    "viz_units = \"metric\"\n",
    "\n",
    "# evaluation scenario definitions - specific variables and configurations to be compared within the overall study\n",
    "\n",
    "# medium range streamflow forecast evaluation files \n",
    "MRF_streamflow = dict(\n",
    "    scenario_name=\"medium_range\",\n",
    "    variable=\"streamflow\",\n",
    "    primary_filepath=Path(STUDY_DIR, \"timeseries\", \"usgs\", \"*.parquet\"),\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"medium_range_mem1\", \"*.parquet\"),\n",
    "    crosswalk_filepath=Path(STUDY_DIR, \"geo\", \"usgs_nwm22_crosswalk.parquet\"),\n",
    "    geometry_filepath=Path(STUDY_DIR, \"geo\", \"usgs_geometry.parquet\")\n",
    ")\n",
    "\n",
    "# medium range precip forecast evaluation files\n",
    "MRF_forcing = dict(\n",
    "    scenario_name=\"medium_range\",\n",
    "    variable=\"precipitation\",    \n",
    "    primary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_analysis_assim\", \"*.parquet\"),\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_medium_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=Path(STUDY_DIR, \"geo\", \"huc10_huc10_crosswalk.parquet\"),                    # the primary and secondary are both HUC10\n",
    "    geometry_filepath=Path(STUDY_DIR, \"geo\", \"huc10_geometry.parquet\"),\n",
    ")\n",
    "\n",
    "# short range streamflow forecast evaluation files \n",
    "SRF_streamflow = dict(\n",
    "    scenario_name=\"short_range\",\n",
    "    variable=\"streamflow\",\n",
    "    primary_filepath=MRF_streamflow[\"primary_filepath\"],\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"short_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=MRF_streamflow[\"crosswalk_filepath\"],\n",
    "    geometry_filepath=MRF_streamflow[\"geometry_filepath\"],\n",
    ")\n",
    "\n",
    "# medium range precip forecast evaluation files\n",
    "SRF_forcing = dict(\n",
    "    scenario_name=\"short_range\",\n",
    "    variable=\"precipitation\",    \n",
    "    primary_filepath=MRF_forcing[\"primary_filepath\"],\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_short_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=MRF_forcing[\"crosswalk_filepath\"],\n",
    "    geometry_filepath=MRF_forcing[\"geometry_filepath\"],\n",
    ")\n",
    "\n",
    "scenario_definitions = [MRF_streamflow, MRF_forcing, SRF_streamflow, SRF_forcing]\n",
    "\n",
    "attribute_paths = dict(\n",
    "    usgs_upstream_area=Path(STUDY_DIR, \"geo\", \"usgs_attr_upstream_area.parquet\"),\n",
    "    usgs_ecoregions=Path(STUDY_DIR, \"geo\", \"usgs_attr_ecoregions.parquet\"),\n",
    "    usgs_stream_order=Path(STUDY_DIR, \"geo\", \"usgs_attr_stream_order.parquet\"),\n",
    "    usgs_huc_crosswalk=Path(STUDY_DIR, \"geo\", \"usgs_huc12_crosswalk.parquet\"),\n",
    ")\n",
    "attribute_df = du.combine_attributes(attribute_paths,viz_units)\n",
    "\n",
    "gage_basins_filepath = Path(\"/home/jovyan/temp/data/gage_basins.parquet\")\n",
    "gage_basins_gdf = gpd.read_parquet(gage_basins_filepath).to_crs(\"EPSG:3857\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa283fae-31fb-4ac4-b3ba-cc664292a389",
   "metadata": {},
   "source": [
    "## Select the scenario and date ranges before launching the dashboard\n",
    "\n",
    "Next we will check the dates available in the parquet files, and use a slider to select all or a portion of the total available period to evaluate.\n",
    "(ToDo: create utility to check that data are complete for all of the above defined timeseries files between the min/max dates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6c8612-2d22-4ebc-b506-fae997f2c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "#huc2_selector = du.get_huc2_selector()\n",
    "scenario_selector = du.get_scenario_selector(scenario_name_list=sorted(du.get_scenario_names(scenario_definitions))) \n",
    "value_time_slider = du.get_value_time_slider(scenario_definitions)\n",
    "pn.Column(pn.Spacer(height=10),\n",
    "          pn.Row(scenario_selector, pn.Spacer(width=20), value_time_slider, width = 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb0b3d-e116-4bfa-9057-1e4cefbffeae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Explore forecast data, one forecast at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fbaa6e-147e-4396-bf1e-dfb5219e1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "include_metrics=['max_perc_diff','max_time_diff']\n",
    "layout = du.post_event_dashboard_2(\n",
    "    scenario_definitions,\n",
    "    scenario_selector,\n",
    "    #huc2_selector,\n",
    "    value_time_slider,\n",
    "    attribute_paths,\n",
    "    include_metrics,\n",
    "    viz_units,\n",
    "    gage_basins_gdf,\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4f6db-b300-41e6-a074-3a9b4ee7b49b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaddbba-c908-4780-823e-f9fdb115558d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbf163e5-8ae4-4ca2-aad3-f8bbf1e04cab",
   "metadata": {},
   "source": [
    "### Below code moved into postevent_dashboard_utils.py to run as function (above), below kept for now for easier troubleshooting if needed, will remove before workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f36dbd-5777-4e78-8d33-8c7d186d6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "\n",
    "######### Build components for the dashboard\n",
    "include_metrics=['max_perc_diff','max_time_diff']\n",
    "\n",
    "huc2_selector = du.get_huc2_selector()\n",
    "metric_selector = du.get_single_metric_selector(\n",
    "    metrics=du.get_metric_selector_dict(metrics=include_metrics))\n",
    "scenarios = du.get_scenario(scenario_definitions, scenario_name=scenario_selector.value)\n",
    "scenario_text = du.get_scenario_text(scenario_selector.value)\n",
    "streamflow_scenario = [s for s in scenarios if s['variable']=='streamflow'][0]\n",
    "precip_scenario = [s for s in scenarios if s['variable']=='precipitation'][0]\n",
    "\n",
    "# reference time player (eventually replace with individual arrows)\n",
    "reference_time_player = du.get_reference_time_player_selected_dates(\n",
    "    scenario=scenarios, \n",
    "    start=value_time_slider[1].value_start-timedelta(hours=1), \n",
    "    end=value_time_slider[1].value_end\n",
    ")\n",
    "current_ref_time = pn.bind(du.get_reference_time_text, reference_time=reference_time_player.param.value)\n",
    "\n",
    "# Some universal plot settings\n",
    "map_opts = dict(show_grid=False, show_legend=False, xaxis = None, yaxis = None, width=600, height=500)\n",
    "ts_opts = dict(toolbar = None, tools=[\"hover\"], show_title = False)\n",
    "\n",
    "# Build background map Elements\n",
    "tiles_background = gv.tile_sources.CartoLight #OSM\n",
    "timeseries_legend = du.get_separate_legend()\n",
    "\n",
    "# link widgets to query and build points element\n",
    "points_bind = pn.bind(\n",
    "    du.build_points_from_query,\n",
    "    scenario = streamflow_scenario,\n",
    "    huc_id=huc2_selector.param.value,\n",
    "    value_time_start=value_time_slider[1].param.value_start,\n",
    "    value_time_end=value_time_slider[1].param.value_end,\n",
    "    reference_time_single=reference_time_player.param.value,\n",
    "    #value_min=0,   \n",
    "    group_by=['primary_location_id','reference_time'],    \n",
    "    include_metrics=include_metrics,#['primary_maximum','max_value_delta','max_value_timedelta'],    \n",
    "    #metric_limits=dict(primary_maximum=(0.1, 10e6)),\n",
    "    plot_metric=metric_selector.param.value,\n",
    "    attribute_paths=attribute_paths,\n",
    "    units=viz_units,\n",
    ")\n",
    "points_dmap = hv.DynamicMap(points_bind)\n",
    "\n",
    "# Define stream source as points selection from points_dmap\n",
    "point_selection = hv.streams.Selection1D(source=points_dmap)#, index=[0])\n",
    "\n",
    "gage_basin_bind = pn.bind(\n",
    "    du.get_gage_basin_selected_point,\n",
    "    index=point_selection.param.index,\n",
    "    points_dmap = points_dmap,  \n",
    "    gage_basins_gdf = gage_basins_gdf,\n",
    "    )\n",
    "gage_basin_dmap = hv.DynamicMap(gage_basin_bind)\n",
    "#gage_basin_dmap.opts(line_color='k', line_width=2, fill_alpha=0)\n",
    "\n",
    "# link selected point to query and build timeseries element\n",
    "hyetograph_bind = pn.bind(\n",
    "    du.build_hyetograph_from_query_selected_point,\n",
    "    index=point_selection.param.index,\n",
    "    points_dmap = points_dmap,          \n",
    "    scenario = precip_scenario,\n",
    "    reference_time_single=reference_time_player.param.value,\n",
    "    value_min=0,     \n",
    "    attribute_paths=attribute_paths,\n",
    "    units=viz_units,\n",
    "    opts = dict(ts_opts, xaxis = None, height=120, width=600),\n",
    ")\n",
    "hydrograph_bind = pn.bind(\n",
    "    du.build_hydrograph_from_query_selected_point,\n",
    "    index=point_selection.param.index,\n",
    "    points_dmap = points_dmap,          \n",
    "    scenario = streamflow_scenario,\n",
    "    reference_time_single=reference_time_player.param.value,  #.value\n",
    "    value_min=0,     \n",
    "    attribute_paths=attribute_paths,\n",
    "    units=viz_units,\n",
    "    opts = dict(ts_opts, height=220, width=600),\n",
    ")\n",
    "\n",
    "###### Apply styles \n",
    "\n",
    "tiles_background.opts(**map_opts)\n",
    "points_dmap.opts(**map_opts, tools=['hover','tap'], colorbar=True, size=5, \n",
    "                 toolbar='above', selection_line_width=5, nonselection_line_width=0, nonselection_alpha=0.5)\n",
    "\n",
    "###### Panel header\n",
    "\n",
    "header = pn.Row(\n",
    "            pn.pane.PNG('https://ciroh.ua.edu/wp-content/uploads/2022/08/CIROHLogo_200x200.png', width=60),\n",
    "            pn.pane.HTML(f\"CIROH Tools for Exploratory Evaluation in Hydrology Research (TEEHR)----Example 1: Forecast Data Exploration<br> - {scenario_text}\", \n",
    "                         sizing_mode=\"stretch_width\", style={'font-size': '18px', 'font-weight': 'bold'}),\n",
    ")\n",
    "# Build the Panel layout\n",
    "layout = \\\n",
    "    pn.Column(\n",
    "        pn.Column(pn.Spacer(height=10), header, width=1100),\n",
    "        pn.Row(\n",
    "            pn.Column(pn.Spacer(height=20), metric_selector, width=200),\n",
    "            pn.Column(pn.Spacer(height=20), huc2_selector, width=200),\n",
    "            pn.Spacer(width=40),\n",
    "            pn.Column(current_ref_time, reference_time_player),\n",
    "            pn.Spacer(width=40), timeseries_legend,\n",
    "        ),\n",
    "        pn.Row(\n",
    "            tiles_background*points_dmap*gage_basin_dmap, \n",
    "            pn.Column(hyetograph_bind, hydrograph_bind),\n",
    "         )\n",
    ")\n",
    "# launch the layout\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c299d81-bd58-4083-9b41-0e52e7090257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
