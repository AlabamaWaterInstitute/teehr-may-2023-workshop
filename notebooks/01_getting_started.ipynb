{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0924ec49-cc42-4625-a61f-fdc6f2f0e736",
   "metadata": {},
   "source": [
    "# 01 - Getting Started\n",
    "The first thing we need to do is install the TEEHR library and make sure we can import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b12a975-6c82-4326-b19f-b031b1e39036",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install 'teehr @ git+https://github.com/RTIInternational/teehr@update-docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d385a1d6-1fcc-45aa-9aa6-baaa9a71d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import teehr.queries.duckdb as tqd\n",
    "import teehr.loading.nwm_point_data as nwmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7569ec6-f0ba-4b17-b8b6-e49d7f7f7351",
   "metadata": {},
   "source": [
    "## Getting Help\n",
    "We have tried to add informative doc strings to the functions that are intended to be utilized by users.  So, for example, in a notebook you can see the doc strings by running `?tqd.get_metrics`.  Most of the functions we will use today have pretty good doc strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68a4c65-bc0b-4312-8bc6-15af6c8161a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtqd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprimary_filepath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msecondary_filepath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcrosswalk_filepath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgroup_by\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0morder_by\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minclude_metrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mteehr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetricEnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfilters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_query\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgeometry_filepath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minclude_geometry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeodataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Calculate performance metrics using database queries.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "primary_filepath : str\n",
       "    File path to the \"observed\" data.  String must include path to file(s)\n",
       "    and can include wildcards.  For example, \"/path/to/parquet/*.parquet\"\n",
       "secondary_filepath : str\n",
       "    File path to the \"forecast\" data.  String must include path to file(s)\n",
       "    and can include wildcards.  For example, \"/path/to/parquet/*.parquet\"\n",
       "crosswalk_filepath : str\n",
       "    File path to single crosswalk file.\n",
       "group_by : List[str]\n",
       "    List of column/field names to group timeseries data by.\n",
       "    Must provide at least one.\n",
       "order_by : List[str]\n",
       "    List of column/field names to order results by.\n",
       "    Must provide at least one.\n",
       "include_metrics = List[str]\n",
       "    List of metrics (see below) for allowable list, or \"all\" to return all\n",
       "    Placeholder, currently ignored -> returns \"all\"\n",
       "filters : Union[List[dict], None] = None\n",
       "    List of dictionaries describing the \"where\" clause to limit data that\n",
       "    is included in metrics.\n",
       "return_query: bool = False\n",
       "    True returns the query string instead of the data\n",
       "include_geometry: bool = True\n",
       "    True joins the geometry to the query results.\n",
       "    Only works if `primary_location_id`\n",
       "    is included as a group_by field.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "results : Union[str, pd.DataFrame, gpd.GeoDataFrame]\n",
       "\n",
       "Filter Order By and Group By Fields\n",
       "-----------------------------------\n",
       "* reference_time\n",
       "* primary_location_id\n",
       "* secondary_location_id\n",
       "* primary_value\n",
       "* secondary_value\n",
       "* value_time\n",
       "* configuration\n",
       "* measurement_unit\n",
       "* variable_name\n",
       "* lead_time\n",
       "\n",
       "Available Metrics\n",
       "-----------------------\n",
       "Basic\n",
       "* primary_count\n",
       "* secondary_count\n",
       "* primary_minimum\n",
       "* secondary_minimum\n",
       "* primary_maximum\n",
       "* secondary_maximum\n",
       "* primary_average\n",
       "* secondary_average\n",
       "* primary_sum\n",
       "* secondary_sum\n",
       "* primary_variance\n",
       "* secondary_variance\n",
       "* max_value_delta\n",
       "    max(secondary_value) - max(primary_value)\n",
       "* bias\n",
       "    sum(primary_value - secondary_value)/count(*)\n",
       "\n",
       "HydroTools Metrics\n",
       "* nash_sutcliffe_efficiency\n",
       "* kling_gupta_efficiency\n",
       "* coefficient_of_extrapolation\n",
       "* coefficient_of_persistence\n",
       "* mean_error\n",
       "* mean_squared_error\n",
       "* root_mean_squared_error\n",
       "\n",
       "Time-based Metrics\n",
       "* primary_max_value_time\n",
       "* secondary_max_value_time\n",
       "* max_value_timedelta\n",
       "\n",
       "Examples:\n",
       "    group_by = [\"lead_time\", \"primary_location_id\"]\n",
       "    order_by = [\"lead_time\", \"primary_location_id\"]\n",
       "    filters = [\n",
       "        {\n",
       "            \"column\": \"primary_location_id\",\n",
       "            \"operator\": \"=\",\n",
       "            \"value\": \"'123456'\"\n",
       "        },\n",
       "        {\n",
       "            \"column\": \"reference_time\",\n",
       "            \"operator\": \"=\",\n",
       "            \"value\": \"'2022-01-01 00:00'\"\n",
       "        },\n",
       "        {\n",
       "            \"column\": \"lead_time\",\n",
       "            \"operator\": \"<=\",\n",
       "            \"value\": \"'10 days'\"\n",
       "        }\n",
       "    ]\n",
       "\u001b[0;31mFile:\u001b[0m      /srv/conda/envs/notebook/lib/python3.10/site-packages/teehr/queries/duckdb.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?tqd.get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f50cce38-39f9-43b6-8543-6ad779479bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mnwmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnwm_to_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvariable_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstart_date\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mingest_days\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlocation_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mjson_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_parquet_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mt_minus_hours\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Fetches NWM point data, formats to tabular, and saves to parquet\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "run : str\n",
       "    NWM forecast category.\n",
       "    (e.g., \"analysis_assim\", \"short_range\", ...)\n",
       "output_type : str\n",
       "    Output component of the configuration.\n",
       "    (e.g., \"channel_rt\", \"reservoir\", ...)\n",
       "variable_name : str\n",
       "    Name of the NWM data variable to download.\n",
       "    (e.g., \"streamflow\", \"velocity\", ...)\n",
       "start_date : str or datetime\n",
       "    Date to begin data ingest.\n",
       "    Str formats can include YYYY-MM-DD or MM/DD/YYYY\n",
       "ingest_days : int\n",
       "    Number of days to ingest data after start date\n",
       "location_ids : Iterable[int]\n",
       "    Array specifying NWM IDs of interest\n",
       "json_dir : str\n",
       "    Directory path for saving json reference files\n",
       "output_parquet_dir : str\n",
       "    Path to the directory for the final parquet files\n",
       "t_minus_hours: Optional[Iterable[int]]\n",
       "    Specifies the look-back hours to include if an assimilation\n",
       "    run is specified.\n",
       "\n",
       "The NWM configuration variables, including run, output_type, and\n",
       "variable_name are stored in the NWM22_RUN_CONFIG dictionary in\n",
       "const_nwm.py.\n",
       "\n",
       "Forecast and assimilation data is grouped and saved one file per reference\n",
       "time, using the file name convention \"YYYYMMDDTHHZ\".  The tabular output\n",
       "parquet files follow the timeseries data model described here:\n",
       "https://github.com/RTIInternational/teehr/blob/main/docs/data_models.md#timeseries  # noqa\n",
       "\u001b[0;31mFile:\u001b[0m      /srv/conda/envs/notebook/lib/python3.10/site-packages/teehr/loading/nwm_point_data.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?nwmp.nwm_to_parquet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
